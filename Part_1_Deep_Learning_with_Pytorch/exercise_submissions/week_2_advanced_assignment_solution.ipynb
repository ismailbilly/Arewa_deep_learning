{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yjk_2Wnn_xA6",
        "outputId": "8048cc23-ea17-4cec-ff95-78055535614d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import PyTorch and matplotlib\n",
        "import torch\n",
        "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import StringIO\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://archive.ics.uci.edu/dataset/607/synchronous+machine+data+set.zip -O data.zip"
      ],
      "metadata": {
        "id": "j46-oAWXACSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip synchronous+machine+data+set.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DevVpZxGGBva",
        "outputId": "99905924-2290-496e-b40b-e8cf77a62baa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  synchronous+machine+data+set.zip\n",
            " extracting: synchronous machine.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"synchronous machine.csv\"\n",
        "data = pd.read_csv(dataset_name, delimiter=';', thousands=',')"
      ],
      "metadata": {
        "id": "jSdhXvheA80O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_data = data.values"
      ],
      "metadata": {
        "id": "eGUw0k6yBrmo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data_tensors = torch.from_numpy(numpy_data)"
      ],
      "metadata": {
        "id": "Cf0LN9kdC4EU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data_tensors.size()"
      ],
      "metadata": {
        "id": "6VGvSjzNECdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee07e80-c868-420c-bff1-5d5477f1b36c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([557, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_pi_tensor = torch.full(original_data_tensors.size(), 3.142)\n",
        "my_pi_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiFJyg6BSwyn",
        "outputId": "6facc6a5-92ea-416f-bc31-f6fb53bfbd53"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
              "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
              "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
              "        ...,\n",
              "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
              "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
              "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU (CUDA) is available\n",
        "device= \"cuda\"\n",
        "if torch.cuda.is_available():\n",
        "    # Move tensors to GPU\n",
        "    original_data_tensors = original_data_tensors.to('cuda')\n",
        "    my_pi_tensor = my_pi_tensor.to('cuda')\n",
        "else: \"cpu\"\n",
        "    # device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "TZqzYxpQTpxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2988902-01da-4eaa-efe0-763b1e95368d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 13 rows of my_p_tensor\n",
        "print(\"First 13 rows of my_p_tensor:\")\n",
        "print(my_pi_tensor[:13, :])\n",
        "\n",
        "# Print the device location of my_p_tensor\n",
        "print(\"\\nTensor device location:\")\n",
        "print(my_pi_tensor.device)\n",
        "\n",
        "# Print the data type of my_p_tensor\n",
        "print(\"\\nTensor data type:\")\n",
        "print(my_pi_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4srUnPgUavb",
        "outputId": "d4f1f848-594e-4f52-f7fc-b759fa39dda4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 13 rows of my_p_tensor:\n",
            "tensor([[3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420],\n",
            "        [3.1420, 3.1420, 3.1420, 3.1420, 3.1420]], device='cuda:0')\n",
            "\n",
            "Tensor device location:\n",
            "cuda:0\n",
            "\n",
            "Tensor data type:\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the 5th root of the sum of my_p_tensor\n",
        "result = torch.pow(torch.sum(my_pi_tensor), 1/5)\n",
        "\n",
        "print(\"5th root of the sum of my_p_tensor:\", result.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUaqGyFwVQKI",
        "outputId": "d0c68091-c4c1-41a5-bc74-dd786841a975"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5th root of the sum of my_p_tensor: 6.143364429473877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the first and last 100 rows\n",
        "my_data_tensor = torch.cat([original_data_tensors[:100], original_data_tensors[-100:]])\n",
        "\n",
        "# Print the new tensor\n",
        "print(my_data_tensor)\n",
        "print(\"my_data_tensor shape:\", my_data_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1sPbAlwV7at",
        "outputId": "71bf8c41-39ea-48d4-e951-9e4b12cc9da0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   3,   66,   34,  383, 1563],\n",
            "        [   3,   68,   32,  372, 1552],\n",
            "        [   3,    7,    3,   36,  154],\n",
            "        [   3,   72,   28,  338, 1518],\n",
            "        [   3,   74,   26,  317, 1497],\n",
            "        [   3,   76,   24,  301, 1481],\n",
            "        [   3,   78,   22,   29,  147],\n",
            "        [   3,    8,    2,   28,  146],\n",
            "        [   3,   82,   18,   25,  143],\n",
            "        [   3,   84,   16,  221, 1401],\n",
            "        [   3,   86,   14,  192, 1372],\n",
            "        [   3,   88,   12,  165, 1345],\n",
            "        [   3,    9,    1,  138, 1318],\n",
            "        [   3,   92,    8,   98, 1278],\n",
            "        [   3,   94,    6,   57, 1237],\n",
            "        [   3,   96,    4,   37, 1217],\n",
            "        [   3,   98,    2,   37, 1217],\n",
            "        [   3,    1,    0,   37, 1217],\n",
            "        [  31,   66,   34,  397, 1577],\n",
            "        [  31,   68,   32,  414, 1594],\n",
            "        [  31,    7,    3,  442, 1622],\n",
            "        [  31,   72,   28,  369, 1549],\n",
            "        [  31,   74,   26,  385, 1565],\n",
            "        [  31,   76,   24,   31,  149],\n",
            "        [  31,   78,   22,  325, 1505],\n",
            "        [  31,    8,    2,  349, 1529],\n",
            "        [  31,   82,   18,   27,  145],\n",
            "        [  31,   84,   16,  277, 1457],\n",
            "        [  31,   86,   14,  193, 1373],\n",
            "        [  31,   88,   12,    2,  138],\n",
            "        [  31,    9,    1,  216, 1396],\n",
            "        [  31,   92,    8,  118, 1298],\n",
            "        [  31,   94,    6,  124, 1304],\n",
            "        [  31,   96,    4,  139, 1319],\n",
            "        [  31,   98,    2,  139, 1319],\n",
            "        [  31,    1,    0,  139, 1319],\n",
            "        [  32,   66,   34,  393, 1573],\n",
            "        [  32,   68,   32,  409, 1589],\n",
            "        [  32,    7,    3,  436, 1616],\n",
            "        [  32,   72,   28,  361, 1541],\n",
            "        [  32,   74,   26,  377, 1557],\n",
            "        [  32,   76,   24,  306, 1486],\n",
            "        [  32,   78,   22,  318, 1498],\n",
            "        [  32,    8,    2,  338, 1518],\n",
            "        [  32,   82,   18,  258, 1438],\n",
            "        [  32,   84,   16,  266, 1446],\n",
            "        [  32,   86,   14,  183, 1363],\n",
            "        [  32,   88,   12,  189, 1369],\n",
            "        [  32,    9,    1,  202, 1382],\n",
            "        [  32,   92,    8,  102, 1282],\n",
            "        [  32,   94,    6,   11,  129],\n",
            "        [  32,   96,    4,  118, 1298],\n",
            "        [  32,   98,    2,  118, 1298],\n",
            "        [  32,    1,    0,  118, 1298],\n",
            "        [  33,   66,   34,  389, 1569],\n",
            "        [  33,   68,   32,  405, 1585],\n",
            "        [  33,    7,    3,   43,  161],\n",
            "        [  33,   72,   28,  355, 1535],\n",
            "        [  33,   74,   26,  369, 1549],\n",
            "        [  33,   76,   24,  303, 1483],\n",
            "        [  33,   78,   22,  312, 1492],\n",
            "        [  33,    8,    2,  328, 1508],\n",
            "        [  33,   82,   18,   25,  143],\n",
            "        [  33,   84,   16,  255, 1435],\n",
            "        [  33,   86,   14,  174, 1354],\n",
            "        [  33,   88,   12,  181, 1361],\n",
            "        [  33,    9,    1,  188, 1368],\n",
            "        [  33,   92,    8,   91, 1271],\n",
            "        [  33,   94,    6,   95, 1275],\n",
            "        [  33,   96,    4,   98, 1278],\n",
            "        [  33,   98,    2,   98, 1278],\n",
            "        [  33,    1,    0,   98, 1278],\n",
            "        [  34,   66,   34,  385, 1565],\n",
            "        [  34,   68,   32,  402, 1582],\n",
            "        [  34,    7,    3,  424, 1604],\n",
            "        [  34,   72,   28,  345, 1525],\n",
            "        [  34,   74,   26,  361, 1541],\n",
            "        [  34,   76,   24,  299, 1479],\n",
            "        [  34,   78,   22,  306, 1486],\n",
            "        [  34,    8,    2,  317, 1497],\n",
            "        [  34,   82,   18,  238, 1418],\n",
            "        [  34,   84,   16,  245, 1425],\n",
            "        [  34,   86,   14,  164, 1344],\n",
            "        [  34,   88,   12,   17,  135],\n",
            "        [  34,    9,    1,  174, 1354],\n",
            "        [  34,   92,    8,   74, 1254],\n",
            "        [  34,   94,    6,    8,  126],\n",
            "        [  34,   96,    4,   77, 1257],\n",
            "        [  34,   98,    2,   77, 1257],\n",
            "        [  34,    1,    0,   77, 1257],\n",
            "        [  35,   66,   34,  372, 1552],\n",
            "        [  35,   68,   32,  395, 1575],\n",
            "        [  35,    7,    3,  418, 1598],\n",
            "        [  35,   72,   28,  328, 1508],\n",
            "        [  35,   74,   26,  349, 1529],\n",
            "        [  35,   76,   24,  285, 1465],\n",
            "        [  35,   78,   22,  296, 1476],\n",
            "        [  35,    8,    2,  306, 1486],\n",
            "        [  35,   82,   18,  216, 1396],\n",
            "        [  35,   84,   16,  225, 1405],\n",
            "        [  55,   81,   19,  366, 1546],\n",
            "        [  55,   83,   17,  377, 1557],\n",
            "        [  55,   85,   15,  389, 1569],\n",
            "        [  55,   87,   13,   25,  143],\n",
            "        [  55,   89,   11,   27,  145],\n",
            "        [  55,   91,    9,  121, 1301],\n",
            "        [  55,   93,    7,   13,  131],\n",
            "        [  55,   95,    5,  138, 1318],\n",
            "        [  55,   97,    3,  138, 1318],\n",
            "        [  55,   99,    1,  138, 1318],\n",
            "        [  56,   65,   35,  736, 1916],\n",
            "        [  56,   67,   33,  729, 1909],\n",
            "        [  56,   69,   31,   74,  192],\n",
            "        [  56,   71,   29,  652, 1832],\n",
            "        [  56,   73,   27,  674, 1854],\n",
            "        [  56,   75,   25,  713, 1893],\n",
            "        [  56,   77,   23,  585, 1765],\n",
            "        [  56,   79,   21,  606, 1786],\n",
            "        [  56,   81,   19,   49,  167],\n",
            "        [  56,   83,   17,  499, 1679],\n",
            "        [  56,   85,   15,  526, 1706],\n",
            "        [  56,   87,   13,  378, 1558],\n",
            "        [  56,   89,   11,  395, 1575],\n",
            "        [  56,   91,    9,  246, 1426],\n",
            "        [  56,   93,    7,  254, 1434],\n",
            "        [  56,   95,    5,  277, 1457],\n",
            "        [  56,   97,    3,  277, 1457],\n",
            "        [  56,   99,    1,  277, 1457],\n",
            "        [  57,   65,   35,  744, 1924],\n",
            "        [  57,   67,   33,   72,   19],\n",
            "        [  57,   69,   31,  735, 1915],\n",
            "        [  57,   71,   29,  641, 1821],\n",
            "        [  57,   73,   27,  661, 1841],\n",
            "        [  57,   75,   25,  697, 1877],\n",
            "        [  57,   77,   23,  573, 1753],\n",
            "        [  57,   79,   21,  591, 1771],\n",
            "        [  57,   81,   19,  472, 1652],\n",
            "        [  57,   83,   17,  481, 1661],\n",
            "        [  57,   85,   15,  506, 1686],\n",
            "        [  57,   87,   13,  359, 1539],\n",
            "        [  57,   89,   11,  375, 1555],\n",
            "        [  57,   91,    9,  226, 1406],\n",
            "        [  57,   93,    7,   23,  141],\n",
            "        [  57,   95,    5,  248, 1428],\n",
            "        [  57,   97,    3,  248, 1428],\n",
            "        [  57,   99,    1,  248, 1428],\n",
            "        [  58,   65,   35,  753, 1933],\n",
            "        [  58,   67,   33,  711, 1891],\n",
            "        [  58,   69,   31,  729, 1909],\n",
            "        [  58,   71,   29,  631, 1811],\n",
            "        [  58,   73,   27,  652, 1832],\n",
            "        [  58,   75,   25,  682, 1862],\n",
            "        [  58,   77,   23,  565, 1745],\n",
            "        [  58,   79,   21,  575, 1755],\n",
            "        [  58,   81,   19,  455, 1635],\n",
            "        [  58,   83,   17,  471, 1651],\n",
            "        [  58,   85,   15,  487, 1667],\n",
            "        [  58,   87,   13,  347, 1527],\n",
            "        [  58,   89,   11,  355, 1535],\n",
            "        [  58,   91,    9,  206, 1386],\n",
            "        [  58,   93,    7,  214, 1394],\n",
            "        [  58,   95,    5,  218, 1398],\n",
            "        [  58,   97,    3,  218, 1398],\n",
            "        [  58,   99,    1,  218, 1398],\n",
            "        [  59,   65,   35,  761, 1941],\n",
            "        [  59,   67,   33,  701, 1881],\n",
            "        [  59,   69,   31,  723, 1903],\n",
            "        [  59,   71,   29,  621, 1801],\n",
            "        [  59,   73,   27,  641, 1821],\n",
            "        [  59,   75,   25,  666, 1846],\n",
            "        [  59,   77,   23,  551, 1731],\n",
            "        [  59,   79,   21,   56,  174],\n",
            "        [  59,   81,   19,  437, 1617],\n",
            "        [  59,   83,   17,  454, 1634],\n",
            "        [  59,   85,   15,  467, 1647],\n",
            "        [  59,   87,   13,  327, 1507],\n",
            "        [  59,   89,   11,  334, 1514],\n",
            "        [  59,   91,    9,  185, 1365],\n",
            "        [  59,   93,    7,  192, 1372],\n",
            "        [  59,   95,    5,  189, 1369],\n",
            "        [  59,   97,    3,  189, 1369],\n",
            "        [  59,   99,    1,  189, 1369],\n",
            "        [   6,   65,   35,  769, 1949],\n",
            "        [   6,   67,   33,  682, 1862],\n",
            "        [   6,   69,   31,  713, 1893],\n",
            "        [   6,   71,   29,  593, 1773],\n",
            "        [   6,   73,   27,  622, 1802],\n",
            "        [   6,   75,   25,  651, 1831],\n",
            "        [   6,   77,   23,  525, 1705],\n",
            "        [   6,   79,   21,  538, 1718],\n",
            "        [   6,   81,   19,  401, 1581],\n",
            "        [   6,   83,   17,  424, 1604],\n",
            "        [   6,   85,   15,  448, 1628],\n",
            "        [   6,   87,   13,   29,  147],\n",
            "        [   6,   89,   11,  301, 1481],\n",
            "        [   6,   91,    9,  142, 1322],\n",
            "        [   6,   93,    7,  151, 1331],\n",
            "        [   6,   95,    5,   16,  134],\n",
            "        [   6,   97,    3,   16,  134],\n",
            "        [   6,   99,    1,   16,  134]], device='cuda:0')\n",
            "my_data_tensor shape: torch.Size([200, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can do\n",
        "# B = A[ row_start : row_end , column_start:column_end].clone()\n",
        "# Extract the 4th column of  and convert it from int to float datatype\n",
        "features = my_data_tensor[:, 3:4].clone().float().to(torch.float32)\n",
        "features[:5]\n",
        "#features.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_FdC8erX5eX",
        "outputId": "d9df40b1-868f-4044-c2be-05ebf651d0e2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[383.],\n",
              "        [372.],\n",
              "        [ 36.],\n",
              "        [338.],\n",
              "        [317.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the last column of  and convert it from int to float dataty\n",
        "target = my_data_tensor[:, -1].clone().detach().float().requires_grad_(True).to(torch.float32)\n",
        "\n",
        "target[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kQ63NKLa2qk",
        "outputId": "e66c265e-de16-416f-adb6-119ab68dde66"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1563., 1552.,  154., 1518., 1497.], device='cuda:0',\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize features\n",
        "features_mean, features_std = features.mean(), features.std()\n",
        "features_normalize  = (features -  features_mean)/ features_std\n",
        "features_tensor = torch.tensor(features_normalize)\n",
        "features_tensor= features_tensor.squeeze(dim=1)\n",
        "features_tensor[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPGPNhtgCKvE",
        "outputId": "352f73ba-4374-4efd-e12f-f5348f2a709e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-d4fd53deb38f>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features_tensor = torch.tensor(features_normalize)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3188,  0.2666, -1.3291,  0.1051,  0.0054], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize target\n",
        "target_mean, target_std = target.mean(), target.std()\n",
        "target_normalize  = (target -  target_mean)/ target_std\n",
        "target_tensor = torch.tensor(target_normalize, dtype=torch.float32 )\n",
        "target_tensor[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G_jdxLqEgG7",
        "outputId": "c622f54e-20c5-43b5-d66e-9c45c1b06bf4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-c724df23ed1d>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target_tensor = torch.tensor(target_normalize, dtype=torch.float32 )\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3992,  0.3767, -2.4802,  0.3072,  0.2643], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_split =int(0.75 *len(features))\n",
        "X_train, y_train= features[:train_split], target[:train_split]\n",
        "X_test, y_test = features[train_split:], target[train_split:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG96Ian9bKkO",
        "outputId": "2f64de2a-1aa5-4f70-be2b-b78917a2380c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 150, 50, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear_layer = nn.Linear(in_features=1,\n",
        "                                      out_features=1)\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_1 = LinearModel()\n",
        "model_1, model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQEDFe363noJ",
        "outputId": "b0d7836f-7885-4c0d-edac-ad0c5eb43325"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(LinearModel(\n",
              "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              " ),\n",
              " OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "              ('linear_layer.bias', tensor([0.8300]))]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr=0.001)"
      ],
      "metadata": {
        "id": "R78V-TqB3z-k"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 100\n",
        "\n",
        "# Put data on the available device\n",
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "    model_1.train().cuda() # train mode is on by default after construction\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model_1(X_train)\n",
        "\n",
        "    # 2. Calculate loss\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. Zero grad optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Step the optimizer i.e update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_1.eval() # put the model in evaluation mode for testing (inference)\n",
        "    # 1. Forward pass\n",
        "    with torch.inference_mode():\n",
        "        test_pred = model_1(X_test)\n",
        "\n",
        "        # 2. Calculate the loss\n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cir2zhoA36mo",
        "outputId": "a73e64f1-558f-4de5-abe7-3db9bd3da4ac"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train loss: 1137.8447265625 | Test loss: 1132.9984130859375\n",
            "Epoch: 20 | Train loss: 760.996826171875 | Test loss: 724.0993041992188\n",
            "Epoch: 40 | Train loss: 753.1162719726562 | Test loss: 771.3173828125\n",
            "Epoch: 60 | Train loss: 753.0445556640625 | Test loss: 776.51806640625\n",
            "Epoch: 80 | Train loss: 753.0410766601562 | Test loss: 776.85595703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    }
  ]
}